{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c82ea6b9",
   "metadata": {},
   "source": [
    "# 2pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "93ebb888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(502, 57, 80)  \n"
     ]
    }
   ],
   "source": [
    "import h5py,os,re,click\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from sympy.combinatorics import Permutation\n",
    "\n",
    "ens='cE211.044.112'\n",
    "\n",
    "path='data_aux/cfgs_run'\n",
    "with open(path,'r') as f:\n",
    "    cfgs=f.read().splitlines()\n",
    "\n",
    "#!============== mom opearations ==============#\n",
    "if True:\n",
    "    def mom2msq(mom):\n",
    "        assert(len(mom)==3)\n",
    "        return mom[0]**2+mom[1]**2+mom[2]**2\n",
    "    def getSortkey_mom(mom): # @mom2standard\n",
    "        msq=mom2msq(mom)\n",
    "        return (msq,-mom[2],-mom[1],-mom[0])\n",
    "    def mom2standard(mom): # @getSortkey_mom\n",
    "        return sorted([abs(mom[0]),abs(mom[1]),abs(mom[2])]) \n",
    "    \n",
    "    elements_rot48=[(sx,sy,sz,xyz) for sx in [1,-1] for sy in [1,-1] for sz in [1,-1] for xyz in [(0,1,2),(0,2,1),(1,0,2),(1,2,0),(2,0,1),(2,1,0)]]\n",
    "    def rotate_mom(e,mom):\n",
    "        if len(mom)!=3:\n",
    "            return rotate_mom(e,mom[:3])+rotate_mom(e,mom[3:])\n",
    "        sx,sy,sz,xyz=e; ix,iy,iz=xyz; iix,iiy,iiz=tuple([ix,iy,iz].index(i) for i in range(3))\n",
    "        return [sx*mom[iix],sy*mom[iiy],sz*mom[iiz]]\n",
    "    def mom2moms(mom):\n",
    "        return [list(mom) for mom in {tuple(rotate_mom(e,mom)) for e in elements_rot48}] \n",
    "    \n",
    "max_mom2=64\n",
    "range_xyz=range(-int(np.sqrt(max_mom2))-1,int(np.sqrt(max_mom2))+2)\n",
    "moms=[[x,y,z] for x in range_xyz for y in range_xyz for z in range_xyz if x**2+y**2+z**2<=max_mom2]       \n",
    "moms=list(set([tuple(mom2standard(mom)) for mom in moms]))\n",
    "moms=[list(mom) for mom in moms]; \n",
    "moms=sorted(moms,key=getSortkey_mom)\n",
    "moms_target=moms\n",
    "\n",
    "def extractFile(paths):\n",
    "    Nsrcs=[]\n",
    "    for ipath,path in enumerate(paths):\n",
    "        with h5py.File(path) as f:\n",
    "            Nsrcs.append(len(f['srcs']))\n",
    "    \n",
    "    dat=0\n",
    "    for ipath,path in enumerate(paths):\n",
    "        with h5py.File(path) as f:\n",
    "            t1=f['data/N1_N1'][:]; t2=f['data/N2_N2'][:]\n",
    "            t=(t1+t2)/2\n",
    "            t=np.mean(t,axis=-1)\n",
    "\n",
    "            t1=f['data_bw/N1_N1'][:]; t2=f['data_bw/N2_N2'][:]\n",
    "            t_bw=(t1+t2)/2\n",
    "            t_bw=np.mean(t_bw,axis=-1)\n",
    "            \n",
    "            t_bw=np.flip(t_bw,axis=0)\n",
    "            # t_bw=t_bw[:,inds_negmom]\n",
    "            t[1:] = (t[1:] + (-1)*t_bw[:])/2\n",
    "            \n",
    "            moms=f['moms'][:]\n",
    "            dic={}\n",
    "            for i,m in enumerate(moms):\n",
    "                dic[tuple(m)]=i\n",
    "\n",
    "            t=np.transpose([np.mean(t[:,[dic[tuple(m)] for m in mom2moms(mom)]],axis=1) for mom in moms_target],[1,0])\n",
    "            \n",
    "            weight=Nsrcs[ipath]/np.sum(Nsrcs)\n",
    "            dat += np.real(t*weight)\n",
    "    return dat\n",
    "    \n",
    "data=[]\n",
    "for icfg,cfg in enumerate(cfgs):\n",
    "    print(f'{icfg}/{len(cfgs)}',end='        \\r')\n",
    "    \n",
    "    path=f'/p/project1/ngff/li47/code/projectData/05_moments/{ens}/data_N_fullmom/{cfg}/'\n",
    "    data.append(extractFile([f'{path}/{file}' for file in os.listdir(path) if ('run4' not in file) and ('run5' not in file)]))\n",
    "\n",
    "data=np.array(data)\n",
    "\n",
    "path=f'/p/project1/ngff/li47/code/projectData/05_moments/{ens}/data_merge/disc_2pt.h5'\n",
    "with h5py.File(path,'w') as f:\n",
    "    f.create_dataset('notes',data=['cfg,time,mom'])\n",
    "    f.create_dataset('cfgs',data=cfgs)\n",
    "    f.create_dataset('moms',data=moms_target)\n",
    "    \n",
    "    f.create_dataset('data/N_N',data=data)\n",
    "\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5fa68500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "nan\n",
      "[ 2.46107790e-15 -3.81415856e-16  3.49291342e-17  3.57388407e-16\n",
      "  8.53975927e-16  7.80924999e-16  4.79007581e-16  5.33046720e-16\n",
      " -1.44957882e-16  3.18241696e-16  1.03906955e-16  1.42702730e-16\n",
      "  5.77656104e-16 -3.12922899e-17 -1.82700774e-16 -4.36704004e-16\n",
      "  1.29725935e-16 -1.09221548e-16  4.34239408e-17 -2.08695079e-16\n",
      " -5.53661195e-16  2.19714450e-16 -1.12713965e-16 -2.13560946e-16\n",
      " -1.12410778e-16  1.84359719e-17 -9.03027616e-17  9.46252541e-17\n",
      " -6.57670394e-18 -1.48712414e-17 -2.79078049e-17 -4.16813053e-17\n",
      " -1.15549787e-16 -5.00490726e-17 -7.93723267e-17 -7.16293254e-17\n",
      " -6.32581620e-17 -2.14147059e-17 -3.80404495e-17 -3.56705479e-17\n",
      "  9.84229745e-17 -6.63137995e-17 -1.03445517e-18 -5.49388277e-17\n",
      " -8.83554253e-17 -6.66834383e-17 -7.08315514e-17  2.09383838e-17\n",
      "  4.10360217e-18 -7.75199047e-17  3.71870619e-17 -3.88928711e-17\n",
      " -6.46847774e-17 -6.64997030e-17 -1.98417746e-17  8.36635383e-17\n",
      " -8.38053486e-18  7.28679059e-18  1.87653486e-17 -1.06752616e-17\n",
      "  1.56068859e-17  1.93202052e-17  3.41712740e-17 -4.08399381e-17\n",
      " -1.60729161e-17 -3.55841053e-17 -9.20218120e-17  5.16561289e-17\n",
      " -3.78088355e-17 -5.90262481e-18 -1.32145532e-16  4.59373802e-17\n",
      " -4.23195750e-18 -4.61333035e-17 -5.91297023e-17 -6.72317940e-17\n",
      "  4.55320673e-17 -5.52550612e-17 -1.90321748e-17 -4.30378658e-17]\n"
     ]
    }
   ],
   "source": [
    "path1='/p/project1/ngff/li47/code/projectData/05_moments/cE211.044.112/data_merge/disc_2pt.h5'\n",
    "path2='/p/project1/ngff/li47/code/projectData/05_moments/cE211.044.112/data_merge/disc_2pt_backup.h5'\n",
    "with h5py.File(path1) as f1, h5py.File(path2) as f2:\n",
    "    cfgs=[cfg.decode() for cfg in f1['cfgs'][:]]\n",
    "    i=cfgs.index('a1084')\n",
    "    print(i)\n",
    "    t1=f1['data/N_N'][:]; t2=f2['data/N_N'][:]\n",
    "    dt=np.abs(t1-t2)\n",
    "    temp=dt/t1\n",
    "    print(temp[i,55,0])\n",
    "    print(t2[i,54])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c744a5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(516, 57, 80)\n",
      "9.273425173223602e-11 b'a1004'\n",
      "7.646136923794442e-11 b'a1012'\n",
      "1.8425699480117928e-10 b'a1020'\n",
      "1.0746743752434451e-10 b'a1028'\n",
      "1.4512983750772364e-10 b'a1036'\n",
      "3.4977430821826045e-10 b'a1044'\n",
      "1.4258298334704638e-10 b'a1052'\n",
      "1.0814061457509883e-10 b'a1060'\n",
      "3.10539464143645e-10 b'a1068'\n",
      "3.069528058612841e-10 b'a1076'\n",
      "nan b'a1084'\n",
      "8.992827472519469e-11 b'a1092'\n",
      "2.0890772631830776e-10 b'a1100'\n",
      "9.70893905088523e-11 b'a1108'\n",
      "4.34860424104679e-10 b'a1116'\n",
      "4.0012981392538195e-10 b'a1124'\n",
      "1.0073325337151087e-10 b'a1132'\n",
      "2.3774357833776957e-10 b'a1140'\n",
      "1.4398083049253604e-10 b'a1148'\n",
      "8.402996268313039e-11 b'a1156'\n",
      "8.636577444121025e-11 b'a1164'\n",
      "7.150897731803244e-11 b'a1172'\n",
      "1.2277031304512847e-10 b'a1180'\n",
      "1.5992544911145234e-10 b'a1188'\n",
      "1.4954005762385053e-10 b'a1196'\n",
      "2.5973303734055776e-10 b'a1204'\n",
      "1.8727740422332892e-10 b'a1212'\n",
      "7.684019666616885e-11 b'a1220'\n",
      "9.717008945173273e-11 b'a1228'\n",
      "nan b'a1236'\n",
      "2.1245540955365226e-10 b'a1244'\n",
      "1.301239810420259e-10 b'a1252'\n",
      "1.4577453585907783e-10 b'a1260'\n",
      "1.270951383648481e-10 b'a1268'\n",
      "8.458008855318473e-11 b'a1276'\n",
      "5.2309950408278005e-11 b'a1284'\n",
      "6.61302323384904e-11 b'a1292'\n",
      "5.145168320534305e-11 b'a1300'\n",
      "1.6023459884998754e-10 b'a1308'\n",
      "2.368949426226191e-10 b'a1316'\n",
      "nan b'b0672'\n",
      "nan b'c1432'\n",
      "nan b'c1872'\n",
      "nan b'd0352'\n"
     ]
    }
   ],
   "source": [
    "path1='/p/project1/ngff/li47/code/projectData/05_moments/cE211.044.112/data_merge/disc_2pt.h5'\n",
    "path2='/p/project1/ngff/li47/code/projectData/05_moments/cE211.044.112/data_merge/disc_2pt_backup.h5'\n",
    "with h5py.File(path1) as f1, h5py.File(path2) as f2:\n",
    "    cfgs=f1['cfgs'][:]\n",
    "    t1=f1['data/N_N'][:]; t2=f2['data/N_N'][:]\n",
    "    dt=np.abs(t1-t2)\n",
    "    print(dt.shape)\n",
    "    dt=np.sum(np.sum(dt,axis=1),axis=1)\n",
    "    for i in range(len(dt)):\n",
    "        if dt[i]!=0:\n",
    "            print(dt[i],cfgs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af3624ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 2109, 2)\n",
      "[ 1.0175419e-10-5.1544950e-13j  2.5773803e-10-1.0312250e-12j\n",
      "  1.6366851e-10-1.3036139e-12j  1.0939998e-10+1.4737686e-12j\n",
      "  4.2120382e-06+1.7305374e+00j            inf          +nanj\n",
      "            inf          +nanj  5.4853951e+30+6.2110817e-01j\n",
      "  2.3872912e-11-1.7985359e+00j -1.1285164e+22+4.4034547e-01j\n",
      "  9.1660281e+35+6.5844530e-01j  2.4737799e-11+1.7469832e+00j\n",
      "  8.5907576e+15-1.4577904e+00j -4.8055490e+14+1.8628734e+00j\n",
      " -3.5569411e+30-4.0908760e-01j -4.3823585e+09+1.6170362e+00j]\n",
      "(inf+nanj)\n"
     ]
    }
   ],
   "source": [
    "path='/p/project1/ngff/li47/code/projectData/05_moments/cE211.044.112/data_N_fullmom/d0352/N.h5_Nrun2_127'\n",
    "with h5py.File(path) as f:\n",
    "    t=f['data/N2_N2']\n",
    "    print(t.shape)\n",
    "    print(t[:16,0,0])\n",
    "    print(t[6,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a1724017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sx79sy20sz87st200 inf\n",
      "sx79sy20sz87st200 0.0\n"
     ]
    }
   ],
   "source": [
    "import tarfile\n",
    "path='/p/project1/ngff/li47/code/projectData/05_moments/cE211.044.112/data_pre/Nrun2_127_arch/0352_r3.tar'\n",
    "with tarfile.open(path) as tar:\n",
    "    for member in tar.getmembers():\n",
    "        if not member.name.endswith('.h5'):\n",
    "            continue\n",
    "        if not ('twop' in member.name):\n",
    "            continue\n",
    "        if not ('sx79sy20sz87st200' in member.name):\n",
    "            continue\n",
    "        fileobj = tar.extractfile(member)\n",
    "        with h5py.File(fileobj) as f:\n",
    "            srcs_old=list(f.keys())\n",
    "            src_old=srcs_old[0]\n",
    "            t=f[src_old]['baryons/nucl_nucl/twop_baryon_2']\n",
    "            print(src_old,t[6,0,0,0])\n",
    "            t=f[src_old]['baryons/nucl_nucl/twop_baryon_1']\n",
    "            print(src_old,t[6,0,0,0])\n",
    "        # break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1125d2df",
   "metadata": {},
   "source": [
    "# jvev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15f146c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "724/725        \r"
     ]
    }
   ],
   "source": [
    "import h5py,os,re,click\n",
    "import numpy as np\n",
    "from itertools import permutations\n",
    "from sympy.combinatorics import Permutation\n",
    "\n",
    "ens='cB211.072.64'\n",
    "\n",
    "jqs=['j+','js','jc'] # disc\n",
    "stouts=range(40+1) # gluon\n",
    "\n",
    "path='data_aux/cfgs_run'\n",
    "with open(path,'r') as f:\n",
    "    cfgs=f.read().splitlines()\n",
    "\n",
    "projs=['P0', 'Px', 'Py', 'Pz']\n",
    "inserts=['tt', 'tx', 'ty', 'tz', 'xx', 'xy', 'xz', 'yy', 'yz', 'zz']\n",
    "inds_trace=[i for i,ins in enumerate(inserts) if ins[0]==ins[1]]\n",
    "\n",
    "xyzt2xyz0=lambda x: x if x!='t' else '0'\n",
    "t=[insert for insert in inserts]; inserts_key=[f'=der:g{xyzt2xyz0(insert[1])}D{xyzt2xyz0(insert[0])}:sym=' for insert in t]\n",
    "\n",
    "def extractVEV(basepath):\n",
    "    j2data={}\n",
    "    \n",
    "    txyz=['t','x','y','z']\n",
    "    Dmus=['d3','d0','d1','d2']\n",
    "    gnus=['gt','gx','gy','gz']\n",
    "    \n",
    "    path=f'{basepath}/j.h5'\n",
    "    with h5py.File(path) as f:\n",
    "        for j in jqs:\n",
    "            gms=[gm.decode() for gm in f['inserts'][:]]\n",
    "            moms_old=f['moms'][:]\n",
    "            dic={}\n",
    "            for i,m in enumerate(moms_old):\n",
    "                dic[tuple(m)]=i\n",
    "            imom=dic[(0,0,0)]\n",
    "            \n",
    "            t=np.array([[f[f'data/{j};{Dmu}'][:,:,gms.index(gnu)] for Dmu in Dmus] for gnu in gnus])\n",
    "            t=t[:,:,:,imom]\n",
    "            t=(t+np.transpose(t,[1,0,2]))/2\n",
    "            t=t - np.eye(4)[:,:,None]*np.trace(t,axis1=0,axis2=1)[None,None,:]/4\n",
    "            t=np.transpose([t[txyz.index(m),txyz.index(n)] for m,n in inserts],[1,0])\n",
    "            \n",
    "            j2data[f'{j};disc']=np.mean(t,axis=0)\n",
    "\n",
    "    path=f'{basepath}/jg.h5'\n",
    "    with h5py.File(path) as f:\n",
    "        gms=[gm.decode() for gm in f['inserts'][:]]\n",
    "        moms_old=f['moms'][:]\n",
    "        dic={}\n",
    "        for i,m in enumerate(moms_old):\n",
    "            dic[tuple(m)]=i\n",
    "        imom=dic[(0,0,0)]\n",
    "        for stout in stouts:\n",
    "            j=f'jg;stout{stout}'\n",
    "            \n",
    "            t=f[f'data/{j}'][:]\n",
    "            t=t[:,imom]\n",
    "            j2data[j]=np.mean(t,axis=0)\n",
    "            \n",
    "    return j2data\n",
    "\n",
    "js=[f'{j};disc' for j in jqs] + [f'jg;stout{stout}' for stout in stouts]\n",
    "j2data={j:[] for j in js}\n",
    "for icfg,cfg in enumerate(cfgs):\n",
    "    print(f'{icfg}/{len(cfgs)}',end='        \\r')\n",
    "    \n",
    "    basepath=f'/p/project1/ngff/li47/code/projectData/02_discNJN_1D/{ens}/data_post_hold/{cfg}/'\n",
    "    j2dat=extractVEV(basepath)\n",
    "    \n",
    "    for j in js:\n",
    "        j2data[j].append(j2dat[j])\n",
    "    # break\n",
    "\n",
    "path=f'/p/project1/ngff/li47/code/projectData/05_moments/{ens}/data_merge/disc_jvev.h5'\n",
    "with h5py.File(path,'w') as f:\n",
    "    for j in j2data.keys():\n",
    "        f.create_dataset(j,data=j2data[j])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
