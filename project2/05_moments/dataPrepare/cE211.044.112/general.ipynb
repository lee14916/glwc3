{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e1080d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cfgs_all_N\n",
    "\n",
    "import os,pickle\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "ens='cE211.044.112'\n",
    "\n",
    "cfg2old=lambda cfg: cfg[1:]+'_r'+{'a':'0','b':'1','c':'2','d':'3'}[cfg[0]]\n",
    "cfg2new=lambda cfg: {'0':'a','1':'b','2':'c','3':'d'}[cfg[-1]] + cfg[:4]\n",
    "\n",
    "path='/p/project1/ngff/li47/code/projectData/05_moments/cE211.044.112/data_pre/Nrun1_100_arch/'\n",
    "cfgs=[cfg2new(cfg) for cfg in os.listdir(path) if not cfg.endswith('.tar')]\n",
    "cfgs.sort()\n",
    "\n",
    "for cfg in cfgs:\n",
    "    files=os.listdir(f'{path}{cfg2old(cfg)}')\n",
    "    assert(len(files)==100)\n",
    "    for file in files:\n",
    "        assert(file.startswith('twop') and file.endswith('.h5'))\n",
    "cfgs_N1=cfgs\n",
    "\n",
    "path=''\n",
    "\n",
    "      \n",
    "# with open('data_aux/cfgs_N','w') as f:\n",
    "#     f.write('\\n'.join(cfgs))\n",
    "\n",
    "len(cfgs_N1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caea4751",
   "metadata": {},
   "source": [
    "# old"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd14dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect data from Bhavna\n",
    "\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "cfg2old=lambda cfg: cfg[1:]+'_r'+{'a':'0','b':'1','c':'2','d':'3'}[cfg[0]]\n",
    "cfg2new=lambda cfg: {'0':'a','1':'b','2':'c','3':'d'}[cfg[-1]] + cfg[:4]\n",
    "\n",
    "path='/p/scratch/renormparton/prasad2/disconnected_boosted/E/twop/nucl-twop-avesrc-updated.h5'\n",
    "with h5py.File(path) as f:\n",
    "    cfgs=[cfg2new(key) for key in f.keys()]; cfgs.sort()\n",
    "    cfgs=cfgs[:]\n",
    "    \n",
    "    t=np.array([[[[f[cfg2old(cfg)][nucl]['msq000']['P0'][fwd]][:] for fwd in ['fwd','bwd']] for nucl in ['nucl1','nucl2']] for cfg in cfgs])\n",
    "    t=(t[:,:,0]-t[:,:,1])/2\n",
    "    t=np.mean(t,axis=1)\n",
    "    t=t[:,0,:,0]\n",
    "    \n",
    "with h5py.File('/p/project1/ngff/li47/code/projectData/05_moments/cE211.044.112/data_merge/disc_2pt.h5','w') as f:\n",
    "    f.create_dataset('cfgs',data=cfgs)\n",
    "    f.create_dataset('moms',data=[[0,0,0]])\n",
    "    f.create_dataset('data/N_N',data=t[:,:,None])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
